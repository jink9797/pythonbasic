1. 데이터 수집
beer = pd.read_csv('C:/python/data/beer.csv')
beer

2. 데이터 탐색
import matplotlib.pyplot as plt
plt.figure(figsize = (5, 5))
plt.scatter(x = beer.temperature, y = beer.beer)
plt.xlabel('temperature')
plt.ylabel('beer')
plt.grid() # 격자 추가
plt.show()


# 독립 변수, 종속 변수 확인
beer.temperature

# 종속 변수 확인, 레코드 수 확인
beer.beer

3. 데이터 준비 - 학습용 / 검증용 데이터 분리
# 학습용 검증용 데이터셋 분리
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(\
                                    x,y, test_size = 0.2, random_state = 1)

4. 모델 구축
from sklearn.linear_model import LinearRegression
lr = LinearRegression()

# 학습 수행
reg = lr.fit(x_train, y_train)

# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성
w1 = reg.coef_[0] # 값만 가져오기
w0 = reg.intercept_
w1

#회귀식
print(f'y = {w1:2f}x + {w0:.5f}')

# 구축된 모델에서 예측 수행
y_pred = reg.predict(x_test)   # 6개의 예측값이 나옴

y_test   # (실제값)

5. 모델 성능 평가
from sklearn.metrics import mean_absolute_error, 
mean_squared_error, r2_score
#MSE

mse = mean_squared_error(y_test, y_pred)

#RMSE

rmse = np.sqrt(mse)

#결정계수 R2
r2 = r2_score(y_test, y_pred)

print(mse, rmse, r2)

6. 시각화
# 수집한 데이터셋 시각화 (예측값 직선 만들기)
## - 원래 x값의 최소보다 조금 작게(xx), 최대보다 조금 크게(yy) 그려야 함
plt.figure(figsize = (5,5))
plt.scatter(beer.temperature, beer.beer)
plt.grid()

# 예측값을 나타내는 선을 만드는 과정(예측선)
xx = np.arange(beer.temperature.min() - 1,  
               beer.temperature.max() + 1)
## - yy는 2차원 배열이니, xx를 2차원 배열로 만들기
yy = reg.predict(xx.reshape(-1, 1))
plt.plot(xx, yy, linestyle = '--', color = 'red')  

plt.xlabel('temperature')
plt.ylabel('beer');

























